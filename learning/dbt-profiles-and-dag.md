# dbt Profiles vÃ  DAG Dependencies - HÆ°á»›ng dáº«n Chi tiáº¿t

## ğŸ“š Má»¥c lá»¥c
1. [dbt Profiles - Quáº£n lÃ½ Káº¿t ná»‘i Database](#1-dbt-profiles---quáº£n-lÃ½-káº¿t-ná»‘i-database)
2. [DAG Dependencies - CÃ¡ch dbt Sáº¯p xáº¿p Thá»© tá»± Cháº¡y Models](#2-dag-dependencies---cÃ¡ch-dbt-sáº¯p-xáº¿p-thá»©-tá»±-cháº¡y-models)
3. [Best Practices](#3-best-practices)
4. [Troubleshooting](#4-troubleshooting)

---

## 1. dbt Profiles - Quáº£n lÃ½ Káº¿t ná»‘i Database

### 1.1. Profiles.yml lÃ  gÃ¬?

**Profiles.yml** lÃ  file cáº¥u hÃ¬nh chá»©a thÃ´ng tin **káº¿t ná»‘i Ä‘áº¿n data warehouse** (credentials, connection strings). File nÃ y **KHÃ”NG NÃŠN commit vÃ o Git** náº¿u chá»©a thÃ´ng tin nháº¡y cáº£m (passwords).

### 1.2. Vá»‹ trÃ­ máº·c Ä‘á»‹nh cá»§a profiles.yml

**Theo máº·c Ä‘á»‹nh**, dbt tÃ¬m `profiles.yml` á»Ÿ:

| OS | ÄÆ°á»ng dáº«n |
|----|-----------|
| **Windows** | `C:\Users\<username>\.dbt\profiles.yml` |
| **macOS** | `~/.dbt/profiles.yml` |
| **Linux** | `~/.dbt/profiles.yml` |

### 1.3. Override vá»‹ trÃ­ profiles.yml

CÃ³ 2 cÃ¡ch Ä‘á»ƒ dbt tÃ¬m `profiles.yml` á»Ÿ vá»‹ trÃ­ khÃ¡c:

#### **CÃ¡ch 1: Sá»­ dá»¥ng flag `--profiles-dir`**
```bash
dbt run --profiles-dir .
dbt run --profiles-dir /path/to/profiles
```

**Ã nghÄ©a:**
- `--profiles-dir .` â†’ TÃ¬m `profiles.yml` á»Ÿ **thÆ° má»¥c hiá»‡n táº¡i**
- Há»¯u Ã­ch khi Ä‘Æ°a `profiles.yml` vÃ o Git (vá»›i hardcoded paths hoáº·c env vars)

#### **CÃ¡ch 2: Sá»­ dá»¥ng biáº¿n mÃ´i trÆ°á»ng `DBT_PROFILES_DIR`**
```bash
# Windows (CMD)
set DBT_PROFILES_DIR=D:\Practice\Scrapy\CrawlJob\dbt_crawjob
dbt run

# Windows (PowerShell)
$env:DBT_PROFILES_DIR="D:\Practice\Scrapy\CrawlJob\dbt_crawjob"
dbt run

# Linux/macOS
export DBT_PROFILES_DIR=/path/to/dbt_project
dbt run
```

**Lá»£i Ã­ch:** KhÃ´ng cáº§n thÃªm `--profiles-dir` má»—i láº§n cháº¡y command.

### 1.4. Cáº¥u trÃºc profiles.yml

#### **VÃ­ dá»¥ cÆ¡ báº£n (DuckDB):**
```yaml
crawljob:                          # Profile name (pháº£i khá»›p vá»›i dbt_project.yml)
  target: dev                       # Target máº·c Ä‘á»‹nh
  outputs:
    dev:                            # Development environment
      type: duckdb                  # Adapter type
      path: "D:\\Practice\\Scrapy\\CrawlJob\\DuckDB\\warehouse.duckdb"
    
    prod:                           # Production environment
      type: duckdb
      path: "/prod/warehouse.duckdb"
```

#### **VÃ­ dá»¥ vá»›i PostgreSQL:**
```yaml
my_project:
  target: dev
  outputs:
    dev:
      type: postgres
      host: localhost
      port: 5432
      user: myuser
      password: mypassword          # âš ï¸ KhÃ´ng commit vÃ o Git!
      dbname: dev_db
      schema: analytics
      threads: 4
    
    prod:
      type: postgres
      host: prod-db.example.com
      port: 5432
      user: "{{ env_var('PROD_DB_USER') }}"          # âœ… DÃ¹ng env vars
      password: "{{ env_var('PROD_DB_PASSWORD') }}"
      dbname: prod_db
      schema: analytics
      threads: 8
```

#### **VÃ­ dá»¥ vá»›i Snowflake:**
```yaml
snowflake_project:
  target: dev
  outputs:
    dev:
      type: snowflake
      account: my_account
      user: dev_user
      password: "{{ env_var('SNOWFLAKE_PASSWORD') }}"
      role: DEV_ROLE
      database: DEV_DB
      warehouse: DEV_WH
      schema: analytics
      threads: 4
```

### 1.5. LiÃªn káº¿t profiles.yml vá»›i dbt_project.yml

Trong `dbt_project.yml`, pháº£i chá»‰ Ä‘á»‹nh profile name:

```yaml
name: 'crawljob'
version: '1.0.0'
profile: 'crawljob'        # â† Pháº£i khá»›p vá»›i tÃªn profile trong profiles.yml
```

### 1.6. Switching giá»¯a Environments (dev/prod)

```bash
# Cháº¡y vá»›i target dev (máº·c Ä‘á»‹nh)
dbt run --profiles-dir .

# Cháº¡y vá»›i target prod
dbt run --profiles-dir . --target prod

# Debug connection
dbt debug --profiles-dir . --target dev
```

### 1.7. Best Practices cho Profiles

| âœ… **NÃŠN** | âŒ **KHÃ”NG NÃŠN** |
|----------|---------------|
| DÃ¹ng `env_var()` cho credentials | Hard-code passwords vÃ o profiles.yml |
| CÃ³ targets riÃªng cho dev/prod | DÃ¹ng chung 1 target cho má»i mÃ´i trÆ°á»ng |
| `.gitignore` profiles.yml náº¿u cÃ³ sensitive data | Commit passwords vÃ o Git |
| DÃ¹ng `--profiles-dir .` cho CI/CD | Rely on `~/.dbt/` trong CI |
| Validate connection vá»›i `dbt debug` | Cháº¡y `dbt run` mÃ  khÃ´ng kiá»ƒm tra connection trÆ°á»›c |

### 1.8. Sá»­ dá»¥ng Environment Variables

**Trong profiles.yml:**
```yaml
crawljob:
  target: dev
  outputs:
    dev:
      type: duckdb
      path: "{{ env_var('DUCKDB_PATH') }}"  # Äá»c tá»« env var
```

**Set env var trÆ°á»›c khi cháº¡y dbt:**
```bash
# Windows CMD
set DUCKDB_PATH=D:\Practice\Scrapy\CrawlJob\DuckDB\warehouse.duckdb
dbt run --profiles-dir .

# Linux/macOS
export DUCKDB_PATH=/path/to/warehouse.duckdb
dbt run --profiles-dir .
```

âš ï¸ **LÆ¯U Ã:** DuckDB adapter cÃ³ thá»ƒ khÃ´ng há»— trá»£ env_var() tá»‘t, nÃªn dÃ¹ng hardcoded path trong profiles.yml.

---

## 2. DAG Dependencies - CÃ¡ch dbt Sáº¯p xáº¿p Thá»© tá»± Cháº¡y Models

### 2.1. DAG (Directed Acyclic Graph) lÃ  gÃ¬?

**DAG** lÃ  **Ä‘á»“ thá»‹ cÃ³ hÆ°á»›ng khÃ´ng cÃ³ chu trÃ¬nh**, dÃ¹ng Ä‘á»ƒ biá»ƒu diá»…n **dependencies** giá»¯a cÃ¡c models.

```
Source (bronze.jobs)
    â†“
Model A (silver.stg_jobs)
    â†“         â†“
Model B      Model C (gold.dim_company, gold.fct_jobs)
```

**Äáº·c Ä‘iá»ƒm:**
- **Directed (CÃ³ hÆ°á»›ng):** A â†’ B nghÄ©a lÃ  B phá»¥ thuá»™c A
- **Acyclic (KhÃ´ng chu trÃ¬nh):** KhÃ´ng cÃ³ vÃ²ng láº·p (A â†’ B â†’ A)

### 2.2. CÃ¡ch dbt PhÃ¡t hiá»‡n Dependencies

dbt **Tá»° Äá»˜NG** phÃ¡t hiá»‡n dependencies báº±ng cÃ¡ch parse **Jinja functions** trong SQL:

#### **HÃ m 1: `{{ source('schema', 'table') }}`**

Tham chiáº¿u Ä‘áº¿n **external table** (Ä‘Ã£ tá»“n táº¡i trong warehouse, khÃ´ng do dbt táº¡o).

**VÃ­ dá»¥:**
```yaml
# models/sources.yml
version: 2
sources:
  - name: bronze               # Source name
    schema: bronze             # Schema trong warehouse
    tables:
      - name: jobs             # Table name
```

```sql
-- models/silver/stg_jobs.sql
SELECT *
FROM {{ source('bronze', 'jobs') }}  -- â† Compile thÃ nh: bronze.jobs
```

**Compile thÃ nh SQL:**
```sql
SELECT * FROM bronze.jobs
```

#### **HÃ m 2: `{{ ref('model_name') }}`**

Tham chiáº¿u Ä‘áº¿n **model khÃ¡c** trong dbt project.

**VÃ­ dá»¥:**
```sql
-- models/gold/fct_jobs.sql
SELECT *
FROM {{ ref('stg_jobs') }}  -- â† Tham chiáº¿u model stg_jobs
```

**Compile thÃ nh SQL:**
```sql
SELECT * FROM silver.stg_jobs
```

**Dependencies:**
```
stg_jobs (silver) â†’ fct_jobs (gold)
```

#### **HÃ m 3: `{{ this }}`**

Tham chiáº¿u Ä‘áº¿n **chÃ­nh model hiá»‡n táº¡i** (dÃ¹ng trong incremental models).

**VÃ­ dá»¥:**
```sql
-- models/silver/stg_jobs.sql
{% if is_incremental() %}
WHERE scraped_at > (SELECT MAX(scraped_at) FROM {{ this }})
{% endif %}
```

**Compile thÃ nh SQL:**
```sql
WHERE scraped_at > (SELECT MAX(scraped_at) FROM silver.stg_jobs)
```

### 2.3. VÃ­ dá»¥: Build DAG cho Project CrawlJob

#### **Step 1: Define Sources**
```yaml
# models/sources.yml
version: 2
sources:
  - name: bronze
    schema: bronze
    tables:
      - name: jobs  # Level 0 - External table
```

#### **Step 2: Silver Layer Model**
```sql
-- models/silver/stg_jobs.sql
{{ config(
  materialized='incremental',
  schema='silver',
  unique_key=['job_url','scraped_date']
) }}

SELECT
  job_url,
  TRIM(job_title) AS job_title,
  LOWER(company_name) AS company_name,
  salary,
  location,
  scraped_at
FROM {{ source('bronze','jobs') }}  -- â† Depends on bronze.jobs

{% if is_incremental() %}
WHERE scraped_at > (SELECT MAX(scraped_at) FROM {{ this }})
{% endif %}
```

**Dependencies:** `bronze.jobs â†’ stg_jobs`

#### **Step 3: Gold Layer Models**
```sql
-- models/gold/dim_company.sql
{{ config(
  materialized='table',
  schema='gold'
) }}

SELECT DISTINCT
  company_name,
  COUNT(*) AS total_jobs
FROM {{ ref('stg_jobs') }}  -- â† Depends on stg_jobs
GROUP BY company_name
```

```sql
-- models/gold/fct_jobs.sql
{{ config(
  materialized='incremental',
  schema='gold',
  unique_key='job_url'
) }}

SELECT
  job_url,
  job_title,
  company_name,
  salary,
  location
FROM {{ ref('stg_jobs') }}  -- â† Depends on stg_jobs
```

**Dependencies:**
```
bronze.jobs (source)
    â†“
stg_jobs (silver)
    â†“              â†“
dim_company    fct_jobs (gold)
```

### 2.4. dbt Execution Order (Topological Sort)

Khi cháº¡y `dbt run`, dbt sáº½:

#### **Step 1: Parse táº¥t cáº£ models**
- Äá»c táº¥t cáº£ `.sql`, `.yml` files
- TÃ¬m `{{ source() }}`, `{{ ref() }}` trong SQL

#### **Step 2: Build DAG**
```
Level 0: bronze.jobs (source - skip)
Level 1: stg_jobs (depends on bronze.jobs)
Level 2: dim_company, fct_jobs (depends on stg_jobs)
```

#### **Step 3: Topological Sort**
Sáº¯p xáº¿p thá»© tá»± execute tá»« upstream â†’ downstream:
```
1. stg_jobs (run first)
2. dim_company, fct_jobs (run in parallel - cÃ¹ng level)
```

#### **Step 4: Execute**
```sql
-- 1. CREATE silver.stg_jobs
CREATE TABLE silver.stg_jobs AS
SELECT ... FROM bronze.jobs;

-- 2. CREATE gold.dim_company (parallel)
CREATE TABLE gold.dim_company AS
SELECT ... FROM silver.stg_jobs;

-- 3. CREATE gold.fct_jobs (parallel)
CREATE TABLE gold.fct_jobs AS
SELECT ... FROM silver.stg_jobs;
```

### 2.5. Visualize DAG

#### **CÃ¡ch 1: dbt Docs**
```bash
cd dbt_crawjob
dbt docs generate --profiles-dir .
dbt docs serve
```

â†’ Má»Ÿ browser táº¡i `http://localhost:8080`, xem **Lineage Graph**.

#### **CÃ¡ch 2: dbt ls (List Resources)**
```bash
# Xem táº¥t cáº£ models
dbt ls --profiles-dir .

# Xem dependencies cá»§a stg_jobs
dbt ls --select +stg_jobs      # Upstream (models mÃ  stg_jobs phá»¥ thuá»™c)
dbt ls --select stg_jobs+      # Downstream (models phá»¥ thuá»™c stg_jobs)
dbt ls --select +stg_jobs+     # Both upstream & downstream

# Xem graph structure
dbt ls --select +stg_jobs+ --output json
```

### 2.6. Node Selection Syntax

dbt cung cáº¥p **powerful syntax** Ä‘á»ƒ cháº¡y subset models:

| Syntax | Ã nghÄ©a | VÃ­ dá»¥ |
|--------|---------|-------|
| `dbt run -s model_name` | Chá»‰ cháº¡y 1 model | `dbt run -s stg_jobs` |
| `dbt run -s +model_name` | Cháº¡y model + táº¥t cáº£ upstream | `dbt run -s +fct_jobs` |
| `dbt run -s model_name+` | Cháº¡y model + táº¥t cáº£ downstream | `dbt run -s stg_jobs+` |
| `dbt run -s +model_name+` | Cháº¡y model + upstream + downstream | `dbt run -s +stg_jobs+` |
| `dbt run -s tag:daily` | Cháº¡y models cÃ³ tag `daily` | `dbt run -s tag:daily` |
| `dbt run -s path:models/silver` | Cháº¡y models trong folder | `dbt run -s path:models/silver` |
| `dbt run -s @model_name` | Cháº¡y model + parents (1 level up) | `dbt run -s @fct_jobs` |
| `dbt run --exclude model_name` | Cháº¡y táº¥t cáº£ trá»« model | `dbt run --exclude stg_jobs` |

**VÃ­ dá»¥ thá»±c táº¿:**
```bash
# Cháº¡y chá»‰ silver layer
dbt run -s path:models/silver --profiles-dir .

# Cháº¡y stg_jobs vÃ  táº¥t cáº£ models downstream (gold)
dbt run -s stg_jobs+ --profiles-dir .

# Cháº¡y táº¥t cáº£ models cáº§n cho fct_jobs (upstream + chÃ­nh nÃ³)
dbt run -s +fct_jobs --profiles-dir .

# Cháº¡y models cÃ³ tag "hourly"
dbt run -s tag:hourly --profiles-dir .
```

### 2.7. Parallel Execution

dbt cháº¡y models **song song** náº¿u chÃºng á»Ÿ **cÃ¹ng level** trong DAG.

**Config threads trong profiles.yml:**
```yaml
crawljob:
  target: dev
  outputs:
    dev:
      type: duckdb
      path: "warehouse.duckdb"
      threads: 4  # â† Sá»‘ lÆ°á»£ng models cháº¡y song song
```

**VÃ­ dá»¥:**
```
stg_jobs (run first - 1 thread)
    â†“
dim_company, fct_jobs, dim_location, agg_daily (run parallel - 4 threads)
```

---

## 3. Best Practices

### 3.1. Naming Conventions

| Layer | Prefix | Schema | VÃ­ dá»¥ |
|-------|--------|--------|-------|
| **Staging** | `stg_` | `silver` | `stg_jobs`, `stg_companies` |
| **Intermediate** | `int_` | `silver` | `int_job_enriched` |
| **Marts (Dimensions)** | `dim_` | `gold` | `dim_company`, `dim_location` |
| **Marts (Facts)** | `fct_` | `gold` | `fct_jobs`, `fct_applications` |
| **Aggregates** | `agg_` | `gold` | `agg_jobs_daily` |

### 3.2. Source() vs Ref()

| HÃ m | Khi nÃ o dÃ¹ng | VÃ­ dá»¥ |
|-----|-------------|--------|
| `{{ source() }}` | External tables (khÃ´ng do dbt táº¡o) | `{{ source('bronze','jobs') }}` |
| `{{ ref() }}` | Models trong dbt project | `{{ ref('stg_jobs') }}` |

**âŒ KHÃ”NG BAO GIá»œ hard-code table names:**
```sql
-- âŒ SAI
SELECT * FROM bronze.jobs
SELECT * FROM silver.stg_jobs

-- âœ… ÄÃšNG
SELECT * FROM {{ source('bronze','jobs') }}
SELECT * FROM {{ ref('stg_jobs') }}
```

**LÃ½ do:**
- dbt khÃ´ng track dependencies náº¿u hard-code
- KhÃ´ng refactor Ä‘Æ°á»£c khi Ä‘á»•i schema/table names

### 3.3. Incremental Models Best Practices

```sql
{{ config(
  materialized='incremental',
  unique_key=['job_url', 'scraped_date'],  -- â† Composite key
  incremental_strategy='merge'              -- â† Merge (upsert) hoáº·c append
) }}

SELECT
  job_url,
  job_title,
  scraped_at
FROM {{ source('bronze','jobs') }}

{% if is_incremental() %}
-- âœ… Filter chá»‰ láº¥y dá»¯ liá»‡u má»›i
WHERE scraped_at > (SELECT COALESCE(MAX(scraped_at), '1970-01-01') FROM {{ this }})
{% endif %}
```

**Chiáº¿n lÆ°á»£c incremental:**
- **`merge`**: Upsert (update existing + insert new) - **Recommend cho most cases**
- **`append`**: Chá»‰ insert má»›i (khÃ´ng update) - **DÃ¹ng cho immutable data**
- **`delete+insert`**: XÃ³a partition cÅ© + insert má»›i - **DÃ¹ng cho partitioned tables**

### 3.4. Schema Organization

```
models/
â”œâ”€â”€ sources.yml           # Define all sources
â”œâ”€â”€ bronze/
â”‚   â””â”€â”€ schema.yml        # Tests cho bronze tables
â”œâ”€â”€ silver/
â”‚   â”œâ”€â”€ stg_jobs.sql
â”‚   â”œâ”€â”€ stg_companies.sql
â”‚   â””â”€â”€ schema.yml        # Tests + descriptions
â”œâ”€â”€ gold/
â”‚   â”œâ”€â”€ dim_company.sql
â”‚   â”œâ”€â”€ fct_jobs.sql
â”‚   â”œâ”€â”€ agg_jobs_daily.sql
â”‚   â””â”€â”€ schema.yml
```

### 3.5. Tags vÃ  Meta

DÃ¹ng tags Ä‘á»ƒ organize vÃ  select models:

```yaml
# models/silver/schema.yml
version: 2
models:
  - name: stg_jobs
    description: "Staging layer for jobs"
    meta:
      owner: "data_team"
      priority: "high"
    config:
      tags: ["daily", "core"]
    columns:
      - name: job_url
        tests:
          - unique
          - not_null
```

**Cháº¡y models theo tags:**
```bash
dbt run -s tag:daily
dbt run -s tag:core
dbt test -s tag:daily
```

---

## 4. Troubleshooting

### 4.1. Lá»—i: "Profile not found"

**Lá»—i:**
```
Runtime Error
  Could not find profile named 'crawljob'
```

**NguyÃªn nhÃ¢n:**
- `profiles.yml` khÃ´ng tá»“n táº¡i hoáº·c á»Ÿ sai vá»‹ trÃ­
- Profile name trong `dbt_project.yml` khÃ´ng khá»›p vá»›i `profiles.yml`

**Giáº£i phÃ¡p:**
```bash
# Kiá»ƒm tra profile
dbt debug --profiles-dir .

# Äáº£m báº£o profile name khá»›p
# dbt_project.yml
profile: 'crawljob'

# profiles.yml
crawljob:  # â† Pháº£i giá»‘ng nhau
  target: dev
```

### 4.2. Lá»—i: Circular Dependencies

**Lá»—i:**
```
Compilation Error
  Found a cycle in the dependency graph: model_a â†’ model_b â†’ model_a
```

**NguyÃªn nhÃ¢n:** Model A ref() Model B, vÃ  Model B ref() Model A.

**Giáº£i phÃ¡p:** Refactor Ä‘á»ƒ break cycle:
```sql
-- Táº¡o model intermediate
-- models/intermediate/int_shared.sql
SELECT ... FROM {{ source('bronze','jobs') }}

-- models/model_a.sql
SELECT ... FROM {{ ref('int_shared') }}

-- models/model_b.sql
SELECT ... FROM {{ ref('int_shared') }}
```

### 4.3. Lá»—i: Model khÃ´ng cháº¡y Ä‘Ãºng thá»© tá»±

**NguyÃªn nhÃ¢n:** KhÃ´ng dÃ¹ng `{{ ref() }}` hoáº·c `{{ source() }}`.

**Giáº£i phÃ¡p:**
```sql
-- âŒ SAI - dbt khÃ´ng biáº¿t dependency
SELECT * FROM silver.stg_jobs

-- âœ… ÄÃšNG
SELECT * FROM {{ ref('stg_jobs') }}
```

### 4.4. Lá»—i: DuckDB khÃ´ng Ä‘á»c env_var()

**Lá»—i:**
```
Database Error in model ...
  No such table: warehouse.duckdb
```

**NguyÃªn nhÃ¢n:** DuckDB adapter khÃ´ng há»— trá»£ env_var() trong path.

**Giáº£i phÃ¡p:** Hardcode path trong profiles.yml:
```yaml
dev:
  type: duckdb
  path: "D:\\Practice\\Scrapy\\CrawlJob\\DuckDB\\warehouse.duckdb"  # â† Hardcoded
```

### 4.5. Lá»—i: Incremental model khÃ´ng filter dá»¯ liá»‡u má»›i

**Lá»—i:** Má»—i láº§n cháº¡y `dbt run`, model incremental váº«n xá»­ lÃ½ toÃ n bá»™ dá»¯ liá»‡u.

**NguyÃªn nhÃ¢n:** Thiáº¿u `{% if is_incremental() %}` filter.

**Giáº£i phÃ¡p:**
```sql
{{ config(materialized='incremental') }}

SELECT * FROM {{ source('bronze','jobs') }}

{% if is_incremental() %}
-- âœ… ThÃªm filter
WHERE scraped_at > (SELECT MAX(scraped_at) FROM {{ this }})
{% endif %}
```

---

## 5. Tá»•ng káº¿t

### âœ… Checklist cho dbt Project

- [ ] `profiles.yml` Ä‘Ã£ cáº¥u hÃ¬nh Ä‘Ãºng vá»›i warehouse
- [ ] `dbt debug --profiles-dir .` cháº¡y thÃ nh cÃ´ng
- [ ] Táº¥t cáº£ models dÃ¹ng `{{ source() }}` vÃ  `{{ ref() }}`, khÃ´ng hard-code table names
- [ ] Incremental models cÃ³ `{% if is_incremental() %}` filter
- [ ] Schema organization: bronze â†’ silver â†’ gold
- [ ] Tests Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong `schema.yml`
- [ ] DAG khÃ´ng cÃ³ circular dependencies
- [ ] Tags Ä‘Æ°á»£c sá»­ dá»¥ng cho scheduling (daily, hourly, etc.)

### ğŸ¯ Key Takeaways

1. **Profiles.yml**: Quáº£n lÃ½ káº¿t ná»‘i database, dÃ¹ng `--profiles-dir .` cho portability
2. **DAG**: dbt tá»± Ä‘á»™ng phÃ¡t hiá»‡n dependencies qua `{{ source() }}` vÃ  `{{ ref() }}`
3. **Execution Order**: Topological sort â†’ upstream models cháº¡y trÆ°á»›c downstream
4. **Best Practices**: LuÃ´n dÃ¹ng `{{ ref() }}` vÃ  `{{ source() }}`, khÃ´ng hard-code table names
5. **Node Selection**: DÃ¹ng `-s`, `+`, tags Ä‘á»ƒ cháº¡y subset models

### ğŸ“š Resources

- [dbt Docs - Profiles](https://docs.getdbt.com/docs/core/connect-data-platform/profiles.yml)
- [dbt Docs - ref() and source()](https://docs.getdbt.com/reference/dbt-jinja-functions/ref)
- [dbt Docs - Node Selection](https://docs.getdbt.com/reference/node-selection/syntax)
- [dbt Docs - Incremental Models](https://docs.getdbt.com/docs/build/incremental-models)
- [dbt Best Practices Guide](https://docs.getdbt.com/guides/best-practices)
