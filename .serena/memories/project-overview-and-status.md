# CrawlJob Project - Complete Architecture Overview

## Project Type
Data pipeline project s·ª≠ d·ª•ng Scrapy ƒë·ªÉ crawl job postings t·ª´ nhi·ªÅu job boards Vietnam, sau ƒë√≥ transform b·∫±ng dbt theo Medallion Architecture.

## Tech Stack
- **Data Collection**: Scrapy (Python)
- **Storage**: PostgreSQL (Bronze), DuckDB (Silver/Gold)
- **Transformation**: dbt Core
- **Orchestration**: Airflow
- **Architecture**: Medallion (Bronze ‚Üí Silver ‚Üí Gold)

## Data Sources (10 job boards)
1. JobOKO (vn.joboko.com)
2. TopCV (topcv.vn)
3. VietnamWorks (vietnamworks.com)
4. ITviec (itviec.vn)
5. LinkedIn
6. CareerLink
7. CareerViet
8. Job123
9. JobsGo
10. JobStreet

## Medallion Architecture

### Bronze Layer
- **Storage**: PostgreSQL
- **Schema**: `bronze.jobs`
- **Data**: Raw data t·ª´ t·∫•t c·∫£ sources
- **Key column**: `source_site` ƒë·ªÉ ph√¢n bi·ªát ngu·ªìn

### Silver Layer ‚≠ê HYBRID APPROACH (Oct 2025)
- **Storage**: DuckDB
- **Schema**: `silver`
- **Main Model**: `stg_jobs.sql` (single file, ~300 lines)
- **Approach**: Hybrid - CASE WHEN per source_site

#### Architecture Decision
**ƒê√£ chuy·ªÉn t·ª´ Source-Specific ‚Üí Hybrid (Oct 6, 2025)**

**L√Ω do:**
- Source-Specific: 13 files, ~1000 lines, 10 queries + UNION
- Hybrid: 1 file, ~300 lines, 1 query duy nh·∫•t
- Performance: 3x faster builds
- Maintainability: 92% fewer files
- Scalability: Th√™m source ch·ªâ c·∫ßn th√™m CASE WHEN

#### File Structure
```
models/silver/
‚îú‚îÄ‚îÄ stg_jobs.sql              # Main staging model (HYBRID)
‚îú‚îÄ‚îÄ schema.yml                # Tests & documentation
‚îú‚îÄ‚îÄ README.md                 # Overview
‚îú‚îÄ‚îÄ README_HYBRID.md          # Implementation details
‚îî‚îÄ‚îÄ MIGRATION_TO_HYBRID.md    # Migration history

analyses/
‚îî‚îÄ‚îÄ staging_data_quality.sql  # Quality monitoring

macros/
‚îî‚îÄ‚îÄ normalize_job_fields.sql  # Helper macros
```

#### Logic Flow (stg_jobs.sql)
```sql
1. source CTE
   - Incremental filter: scraped_at > max(scraped_at)

2. base_cleaning CTE
   - Common normalization for ALL sources
   - clean_whitespace() macro
   - Keep raw fields: salary_raw, experience_raw, etc.

3. source_specific CTE
   - CASE WHEN by source_site
   - Salary normalization per source
   - Experience normalization per source
   - Education normalization per source
   - Location cleaning per source
   - Source name mapping

4. final CTE
   - Column selection & ordering
```

#### Source-Specific Normalization

**JobOKO (vn.joboko.com):**
- Salary: "Th·ªèa thu·∫≠n" ‚Üí "Negotiable", "C·∫°nh tranh" ‚Üí "Competitive"
- Location: Remove "Khu v·ª±c:" / "ƒê·ªãa ƒëi·ªÉm:" prefix
- Experience: "D∆∞·ªõi 1 nƒÉm" ‚Üí "< 1 year", "1-2 nƒÉm" ‚Üí "1-2 years", "2-5 nƒÉm" ‚Üí "2-5 years", "Tr√™n 5 nƒÉm" ‚Üí "5+ years"

**TopCV (topcv.vn):**
- Salary: "Th·ªèa thu·∫≠n" ‚Üí "Negotiable", "Up to X tri·ªáu" preserved
- Education: "ƒê·∫°i h·ªçc" ‚Üí "Bachelor", "Cao ƒë·∫≥ng" ‚Üí "Associate", "Th·∫°c sƒ©" ‚Üí "Master", "Ti·∫øn sƒ©" ‚Üí "PhD"
- Experience: "1 nƒÉm" ‚Üí "1 year", "2 nƒÉm" ‚Üí "2 years", "Tr√™n 5 nƒÉm" ‚Üí "5+ years"

**VietnamWorks (vietnamworks.com):**
- Salary: "You'll love it" ‚Üí "Attractive", USD preserved
- Experience: English terms (Experienced, Manager, Senior, Junior)
- Education: English terms (Bachelor, Master, PhD, etc.)

**Others (ITviec, LinkedIn, etc.):**
- Generic normalization
- Basic patterns: "Th·ªèa thu·∫≠n" / "Negotiable" ‚Üí "Negotiable"

#### Configuration
- **Materialized**: incremental
- **Unique Key**: job_url
- **Incremental Strategy**: merge
- **Schema**: silver
- **Tags**: ['staging', 'hybrid']

#### Helper Macros
- `clean_whitespace(column)`: Trim + remove extra spaces
- `normalize_deadline(column)`: Format DD/MM/YYYY

### Gold Layer
- Ch∆∞a implement chi ti·∫øt
- S·∫Ω consume t·ª´ `stg_jobs`

## Data Quality

### dbt Tests (schema.yml)
- **Unique**: job_url
- **Not null**: job_url, job_title, company_name, source_site, source_name, scraped_at, scraped_date
- **Accepted values**: source_name (10 sources + unknown)
- **Custom tests**: 
  - `valid_url`: Check URL format
  - `valid_source_site`: Check source_site values
  - `is_recent`: scraped_at within 7 days
  - `deadline_after_scraped`: job_deadline >= scraped_at
  - `salary_has_currency`: Check salary format

### Quality Monitoring (staging_data_quality.sql)
1. Overall statistics (rows, sources, companies)
2. Per-source statistics (jobs, completeness)
3. Field completeness percentage
4. Salary normalization check
5. Experience distribution
6. Recent data check (7 days)
7. Quality issues detection
8. Top companies by source

## Performance Metrics

### Before (Source-Specific)
- Files: 13
- Lines of code: ~1000
- Build time: ~30s
- Queries: 10 + UNION ALL

### After (Hybrid)
- Files: 1 main model
- Lines of code: ~300
- Build time: ~10s (3x faster)
- Queries: 1 single query

## Adding New Source

**Process (Hybrid Approach):**
1. Open `stg_jobs.sql`
2. Add CASE WHEN for salary normalization (~3 lines)
3. Add CASE WHEN for experience normalization (~3 lines)
4. Add CASE WHEN for education if needed (~3 lines)
5. Add source_name mapping (~1 line)

**Total: ~10 lines code in 1 file**

**Example:**
```sql
when source_site = 'glints.com' then
  case
    when lower(salary_raw) like '%undisclosed%' then 'Negotiable'
    else trim(salary_raw)
  end
```

## Commands Reference

### Build
```bash
dbt run --select stg_jobs
dbt run --select stg_jobs --full-refresh
```

### Test
```bash
dbt test --select stg_jobs
dbt test --select stg_jobs --select test_name:unique
```

### Quality Check
```bash
dbt compile --select staging_data_quality
# Run compiled SQL in database
```

### Documentation
```bash
dbt docs generate
dbt docs serve
```

## Best Practices Applied

1. ‚úÖ **DRY Principle**: Macros for reusable logic
2. ‚úÖ **Performance**: Single query, incremental updates
3. ‚úÖ **Maintainability**: 1 file vs 10+ files
4. ‚úÖ **Documentation**: Inline comments + README files
5. ‚úÖ **Testing**: Comprehensive dbt tests
6. ‚úÖ **Scalability**: Easy to add new sources
7. ‚úÖ **Community Standards**: dbt + Medallion best practices
8. ‚úÖ **Monitoring**: Quality check queries

## Migration History

### Oct 5, 2025: Initial Source-Specific Implementation
- Created 10+ staging models (one per source)
- Created stg_jobs_unified.sql (UNION ALL)
- Pros: Clear separation, easy to test per source
- Cons: Too many files, code duplication, slow performance

### Oct 6, 2025: Migration to Hybrid Approach
- **Deleted**: 10 source-specific models, UNION model, staging folder
- **Created**: Single stg_jobs.sql with CASE WHEN logic
- **Result**: 92% fewer files, 70% less code, 3x faster
- **Status**: Production ready

## Key Decisions & Rationale

### Why Hybrid over Source-Specific?
1. **Scale**: 10 sources kh√¥ng qu√° nhi·ªÅu ƒë·ªÉ justify 10 files
2. **Maintenance**: 1 file d·ªÖ maintain h∆°n 13 files
3. **Performance**: 1 query t·ªët h∆°n 10 queries + UNION
4. **DRY**: CASE WHEN + macros tr√°nh code duplication
5. **Community**: dbt best practice "fewer, larger models"

### Why NOT 3NF in Silver?
- Silver layer focus: Clean + Standardize, not normalize relations
- 3NF t·ªët cho OLTP, kh√¥ng c·∫ßn thi·∫øt cho analytics
- Wide tables d·ªÖ query h∆°n cho downstream
- Gold layer s·∫Ω handle business modeling (star schema, etc.)

## Future Enhancements

### Short-term
- [ ] Add remaining sources (ITviec, LinkedIn v·ªõi logic chi ti·∫øt)
- [ ] Implement Gold layer (fact/dim tables)
- [ ] Add data quality alerts
- [ ] Setup CI/CD for dbt

### Long-term
- [ ] Add data profiling
- [ ] Implement SCD Type 2 for company changes
- [ ] Add machine learning features
- [ ] Build semantic layer

## Documentation Files

1. **models/silver/README.md**: Overview & quick start
2. **models/silver/README_HYBRID.md**: Implementation details
3. **models/silver/MIGRATION_TO_HYBRID.md**: Migration guide
4. **models/silver/schema.yml**: Column descriptions & tests
5. **analyses/staging_data_quality.sql**: Quality monitoring queries

## Status

üéâ **Silver Layer: PRODUCTION READY**
- Architecture: Hybrid (single file + CASE WHEN)
- Files: Cleaned & organized
- Tests: Comprehensive
- Documentation: Complete
- Performance: Optimized
- Next: Implement Gold layer
