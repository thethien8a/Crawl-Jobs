# Project: CrawlJob

## ğŸ¯ Current State
- **Phase**: Phase 2 in progress (FastAPI completed)
- **Progress**: 10/12 tasks completed
- **Next Goal**: Exporters and optimization improvements

## âœ… Completed Tasks
- [x] Implement spiders: JobsGO, JobOKO, 123job, CareerViet
- [x] SQL Server pipeline: create table if missing, insert items
- [x] CLI runner `run_spider.py` with FEEDS to export JSON
- [x] Environment-based DB configuration via `.env` (python-dotenv)
- [x] Basic throttling config and custom User-Agent
- [x] Dedup & Unique Constraint â€” unique on `(source_site, job_url)`; prevent duplicates (completed)
- [x] Upsert (Insert-or-Update) + `updated_at` â€” update existing rows and set `updated_at` (completed)
- [x] Structured Logging (Ä‘Æ°á»£c chá»§ dá»± Ã¡n xÃ¡c nháº­n bá» qua vÃ  coi nhÆ° hoÃ n táº¥t)
- [x] API Read-Only Service (FastAPI) â€” implemented with /health and /jobs endpoints (completed)
- [x] Incremental Crawling & Scheduling â€” added `crawl_daily.bat` and README Scheduling section; supports daily runs with logs/outputs (completed)

## ğŸ”„ Pending Tasks
### Phase 2: Web App MVP (HIGH PRIORITY)
- [ ] Exporters: CSV/Parquet (45 minutes)
  - **Objective**: Há»— trá»£ xuáº¥t CSV/Parquet ngoÃ i JSON.
  - **Why?**: Linh hoáº¡t tÃ­ch há»£p BI/ML.
  - **Files to modify**: `run_spider.py` (tham sá»‘ `--output-format`), README.
  - **Acceptance Criteria**: Táº¡o Ä‘Æ°á»£c file `.csv`/`.parquet` vá»›i schema á»•n Ä‘á»‹nh.
  - **Test Cases**: So sÃ¡nh sá»‘ báº£n ghi giá»¯a DB vÃ  file export.

### Phase 3: Optimization (MEDIUM PRIORITY)
- [ ] AutoThrottle & Rotating User-Agent/Proxies (1.5 hours)
  - **Objective**: Giáº£m rate-limit/rÃ ng buá»™c bot.
  - **Why?**: á»”n Ä‘á»‹nh crawl khi quy mÃ´ lá»›n.
  - **Files to modify**: `settings.py` (AutoThrottle), middleware UA/proxy.
  - **Acceptance Criteria**: Giáº£m lá»—i 429/ban; tá»‘c Ä‘á»™ crawl á»•n Ä‘á»‹nh.
  - **Test Cases**: So sÃ¡nh thá»i gian/ lá»—i trÆ°á»›c-sau.

- [ ] Selector Resilience (1.5 hours)
  - **Objective**: Chuáº©n hoÃ¡ selector theo module vÃ  fallback Ä‘a chiáº¿n lÆ°á»£c.
  - **Why?**: Giáº£m vá»¡ khi HTML thay Ä‘á»•i nhá».
  - **Files to modify**: `spiders/` (trÃ­ch chung hÃ m extract, regex labels), `utils.py`.
  - **Acceptance Criteria**: 90% trang thay Ä‘á»•i nháº¹ váº«n parse Ä‘Æ°á»£c cÃ¡c trÆ°á»ng chÃ­nh.
  - **Test Cases**: Bá»™ trang máº«u (cÅ©/má»›i) parse á»•n.

- [ ] Basic Tests (1 hour)
  - **Objective**: ThÃªm unit test cho utils vÃ  pipeline; fake HTML cho parser.
  - **Why?**: Báº£o vá»‡ chá»©c nÄƒng cá»‘t lÃµi.
  - **Files to modify**: `tests/` má»›i; CI cÃ¢n nháº¯c sau.
  - **Acceptance Criteria**: `pytest` pass; coverage tá»‘i thiá»ƒu cho utils/pipeline.

### Phase 4: Advanced Features (LOW PRIORITY)
- [ ] Enrichment & NLP (4 hours)
  - **Objective**: Chuáº©n hoÃ¡ trÆ°á»ng (má»©c lÆ°Æ¡ng, Ä‘á»‹a Ä‘iá»ƒm), trÃ­ch ká»¹ nÄƒng, phÃ¢n loáº¡i ngÃ nh.
  - **Why?**: TÄƒng giÃ¡ trá»‹ phÃ¢n tÃ­ch downstream.
  - **Files to modify**: Module `enrichment/` (chuáº©n hoÃ¡, mapping, NLP cÆ¡ báº£n), thÃªm cá»™t má»›i náº¿u cáº§n.
  - **Acceptance Criteria**: Tá»· lá»‡ parse chuáº©n hoÃ¡ >80% cho máº«u thá»­.

- [ ] Analytics Dashboard (2 hours)
  - **Objective**: Metabase/PowerBI/Streamlit dashboard nhanh.
  - **Why?**: Trá»±c quan hoÃ¡ sá»‘ liá»‡u.
  - **Files to modify**: TÃ i liá»‡u cáº¥u hÃ¬nh + script káº¿t ná»‘i.
  - **Acceptance Criteria**: Xem Ä‘Æ°á»£c top cÃ´ng ty, má»©c lÆ°Æ¡ng theo vá»‹ trÃ­.

## ğŸ“Š Workflow Visualization
```mermaid
graph TD
    subgraph "Phase 1: Quick Wins"
        A[Dedup & Unique] --> B[Upsert + updated_at]
        B --> C[Structured Logging]
    end
    subgraph "Phase 2: Core Implementation"
        C --> D[FastAPI Read API]
        D --> E[CSV/Parquet Export]
        E --> F[Incremental & Scheduling]
    end
    subgraph "Phase 3: Optimization"
        F --> G[AutoThrottle & Rotating UA/Proxies]
        G --> H[Selector Resilience]
        H --> I[Basic Tests]
    end
    subgraph "Phase 4: Advanced"
        I --> J[Enrichment & NLP]
        J --> K[Analytics Dashboard]
    end
```

## ğŸ¯ Next Actions
1. Exporters CSV/Parquet
2. AutoThrottle optimization
3. Selector resilience + basic tests

## ğŸ“Š Progress Tracking
- **Total tasks**: 12
- **Completed**: 10
- **Remaining**: 2
- **Estimated time**: ~5.5â€“6 hours

## ğŸ¯ Success Criteria
- [ ] KhÃ´ng cÃ²n trÃ¹ng láº·p theo `job_url` sau nhiá»u láº§n crawl
- [ ] CÃ³ API read-only Ä‘á»ƒ tiÃªu thá»¥ dá»¯ liá»‡u
- [ ] Crawl á»•n Ä‘á»‹nh vá»›i AutoThrottle vÃ  UA/Proxy
- [ ] CÃ³ test cÆ¡ báº£n báº£o vá»‡ pipeline vÃ  utils
