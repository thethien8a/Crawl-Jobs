# CrawlJob - Professional Data Engineering Project ğŸ‰

Há»‡ thá»‘ng ká»¹ thuáº­t dá»¯ liá»‡u chuyÃªn nghiá»‡p Ä‘á»ƒ thu tháº­p, kiá»ƒm tra cháº¥t lÆ°á»£ng, biáº¿n Ä‘á»•i vÃ  trá»±c quan hÃ³a dá»¯ liá»‡u viá»‡c lÃ m tá»« **10 trang tuyá»ƒn dá»¥ng hÃ ng Ä‘áº§u Viá»‡t Nam**. Dá»± Ã¡n nÃ y khÃ´ng chá»‰ lÃ  má»™t cÃ´ng cá»¥ scraping mÃ  cÃ²n lÃ  má»™t pipeline dá»¯ liá»‡u hoÃ n chá»‰nh, sáºµn sÃ ng cho cÃ¡c tÃ¡c vá»¥ phÃ¢n tÃ­ch vÃ  há»c mÃ¡y.

## ğŸ—ï¸ Kiáº¿n trÃºc Há»‡ thá»‘ng

Dá»± Ã¡n Ä‘Æ°á»£c xÃ¢y dá»±ng theo kiáº¿n trÃºc hiá»‡n Ä‘áº¡i, tÃ¡ch biá»‡t rÃµ rÃ ng cÃ¡c thÃ nh pháº§n, bao gá»“m:
- **Thu tháº­p dá»¯ liá»‡u (Ingestion)**: `Scrapy` & `Selenium` & `BeautifulSoup`
- **Äiá»u phá»‘i (Orchestration)**: `Apache Airflow`
- **LÆ°u trá»¯ (Storage)**: `PostgreSQL` (OLTP) & `DuckDB` (OLAP)
- **Kiá»ƒm tra cháº¥t lÆ°á»£ng (Data Quality)**: `Great Expectations`
- **Biáº¿n Ä‘á»•i dá»¯ liá»‡u (Transformation)**: `dbt`
- **API & Giao diá»‡n (Presentation)**: `FastAPI` & `Vanilla JS`
- **Trá»±c quan hÃ³a (BI)**: `Apache Superset`

```mermaid
flowchart TD
    subgraph ingestion["ğŸ”„ Data Ingestion"]
        spiders["ğŸ•·ï¸ CrawlJob Spiders"]
        airflow["âš¡ Apache Airflow"]
    end
    subgraph storage["ğŸ’¾ Data Storage"]
        postgres["ğŸ˜ PostgreSQL (OLTP)"]
        duckdb["ğŸ¦† DuckDB (OLAP)"]
    end
    subgraph processing["âš™ï¸ Data Processing"]
        dbt["ğŸ”¨ dbt (Transform)"]
        ge["âœ… Great Expectations (Validate)"]
    end
    subgraph presentation["ğŸ“Š Presentation & Access"]
        superset["Apache Superset (BI)"]
        fastapi["ğŸš€ FastAPI (API)"]
        webapp["ğŸŒ Web App"]
    end
    airflow --> spiders --> postgres
    airflow --> ge --> postgres
    airflow --> dbt
    dbt --> postgres
    dbt --> duckdb
    fastapi --> postgres
    webapp --> fastapi
    superset --> duckdb
```

## ğŸš€ Báº¯t Ä‘áº§u nhanh (Getting Started)

### YÃªu cáº§u
- Python 3.10+
- Docker & Docker Compose
- Git

### CÃ i Ä‘áº·t & Cáº¥u hÃ¬nh

Thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau theo Ä‘Ãºng thá»© tá»± Ä‘á»ƒ cÃ i Ä‘áº·t mÃ´i trÆ°á»ng development.

**1. Clone Repository**
```bash
git clone <your-repository-url>
cd CrawlJob
```

**2. Táº¡o vÃ  kÃ­ch hoáº¡t MÃ´i trÆ°á»ng áº£o**
```bash
# Táº¡o mÃ´i trÆ°á»ng áº£o
python -m venv .venv

# KÃ­ch hoáº¡t (Windows)
.\.venv\Scripts\activate
```

**3. CÃ i Ä‘áº·t cÃ¡c gÃ³i phá»¥ thuá»™c**
```bash
pip install -r requirements.txt
```

**4. Cáº¥u hÃ¬nh Biáº¿n mÃ´i trÆ°á»ng**
Copy file `.env.example` thÃ nh file `.env` vÃ  Ä‘iá»n cÃ¡c thÃ´ng tin cáº§n thiáº¿t.
```bash
# Windows
copy .env.example .env
```
Sau Ä‘Ã³, má»Ÿ file `.env` vÃ  Ä‘iá»n thÃ´ng tin Ä‘Äƒng nháº­p PostgreSQL, tÃ i khoáº£n ITviec, LinkedIn, v.v.

**5. Khá»Ÿi Ä‘á»™ng Database**
Dá»± Ã¡n sá»­ dá»¥ng PostgreSQL cháº¡y trong Docker. HÃ£y khá»Ÿi Ä‘á»™ng container:
```bash
docker-compose up -d
```
Lá»‡nh nÃ y sáº½ khá»Ÿi Ä‘á»™ng má»™t service PostgreSQL cÃ³ thá»ƒ truy cáº­p táº¡i `localhost:5432`.

```
Lá»‡nh nÃ y sáº½ há»i báº¡n má»™t vÃ i cÃ¢u, hÃ£y nháº¥n `Enter` Ä‘á»ƒ cháº¥p nháº­n cÃ¡c giÃ¡ trá»‹ máº·c Ä‘á»‹nh.

**6. Cháº¡y thá»­ nghiá»‡m**
BÃ¢y giá» báº¡n Ä‘Ã£ sáºµn sÃ ng! HÃ£y thá»­ cháº¡y má»™t spider Ä‘á»ƒ kiá»ƒm tra:
```bash
python run_spider.py --spider itviec --keyword "Data Engineer"
```
Dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c thu tháº­p vÃ  lÆ°u vÃ o database PostgreSQL cá»§a báº¡n.

## ğŸ“– HÆ°á»›ng dáº«n sá»­ dá»¥ng

### Cháº¡y Spiders
Sá»­ dá»¥ng script `run_spider.py` Ä‘á»ƒ thá»±c thi viá»‡c thu tháº­p dá»¯ liá»‡u.

```bash
# Cháº¡y má»™t spider cá»¥ thá»ƒ
python run_spider.py --spider topcv --keyword "Product Manager"

# Cháº¡y táº¥t cáº£ 10 spiders
python run_spider.py --spider all --keyword "IT"
```

### Cháº¡y API Server
API cung cáº¥p dá»¯ liá»‡u Ä‘Ã£ thu tháº­p cho giao diá»‡n web.
```bash
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```
- **Health check**: `http://localhost:8000/health`
- **TÃ¬m kiáº¿m jobs**: `http://localhost:8000/jobs?keyword=python`

### Kiá»ƒm tra cháº¥t lÆ°á»£ng dá»¯ liá»‡u (Data Quality) (Great Expectations)
Sau khi thu tháº­p dá»¯ liá»‡u, báº¡n cÃ³ thá»ƒ cháº¡y quy trÃ¬nh kiá»ƒm tra cháº¥t lÆ°á»£ng Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a.
```bash
# Lá»‡nh nÃ y sáº½ Ä‘Æ°á»£c tÃ­ch há»£p vÃ o Airflow trong pipeline hoÃ n chá»‰nh
python validation/run_checkpoint.py <tÃªn_checkpoint>
```

## ğŸ› ï¸ CÃ´ng nghá»‡ sá»­ dá»¥ng

- **Scrapy & Selenium**: LÃµi thu tháº­p dá»¯ liá»‡u, vá»›i kháº£ nÄƒng vÆ°á»£t qua Cloudflare.
- **PostgreSQL & Docker**: LÆ°u trá»¯ dá»¯ liá»‡u thÃ´, dá»… dÃ ng cÃ i Ä‘áº·t vÃ  quáº£n lÃ½.
- **Great Expectations**: Äáº£m báº£o tÃ­nh toÃ n váº¹n vÃ  cháº¥t lÆ°á»£ng cá»§a dá»¯ liá»‡u.
- **FastAPI**: XÃ¢y dá»±ng API hiá»‡u nÄƒng cao.
- **VÃ  cÃ¡c cÃ´ng cá»¥ khÃ¡c trong DE Stack**: Airflow, dbt, DuckDB, Superset.

## ğŸ¤ ÄÃ³ng gÃ³p
Náº¿u báº¡n cÃ³ Ã½ tÆ°á»Ÿng cáº£i thiá»‡n dá»± Ã¡n, Ä‘á»«ng ngáº§n ngáº¡i táº¡o Pull Request hoáº·c má»Ÿ má»™t Issue.
