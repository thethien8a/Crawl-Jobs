# CrawlJob - Professional Data Engineering Project üéâ

H·ªá th·ªëng k·ªπ thu·∫≠t d·ªØ li·ªáu chuy√™n nghi·ªáp ƒë·ªÉ thu th·∫≠p, ki·ªÉm tra ch·∫•t l∆∞·ª£ng, bi·∫øn ƒë·ªïi v√† tr·ª±c quan h√≥a d·ªØ li·ªáu vi·ªác l√†m t·ª´ **10 trang tuy·ªÉn d·ª•ng h√†ng ƒë·∫ßu Vi·ªát Nam**. D·ª± √°n n√†y kh√¥ng ch·ªâ l√† m·ªôt c√¥ng c·ª• scraping m√† c√≤n l√† m·ªôt pipeline d·ªØ li·ªáu ho√†n ch·ªânh, s·∫µn s√†ng cho c√°c t√°c v·ª• ph√¢n t√≠ch v√† h·ªçc m√°y.

## üèóÔ∏è Ki·∫øn tr√∫c H·ªá th·ªëng

D·ª± √°n ƒë∆∞·ª£c x√¢y d·ª±ng theo ki·∫øn tr√∫c hi·ªán ƒë·∫°i, t√°ch bi·ªát r√µ r√†ng c√°c th√†nh ph·∫ßn, bao g·ªìm:
- **Thu th·∫≠p d·ªØ li·ªáu (Ingestion)**: `Scrapy` & `Selenium` & `BeautifulSoup`
- **ƒêi·ªÅu ph·ªëi (Orchestration)**: `Apache Airflow`
- **L∆∞u tr·ªØ (Storage)**: `PostgreSQL` (OLTP) & `DuckDB` (OLAP)
- **Ki·ªÉm tra ch·∫•t l∆∞·ª£ng (Data Quality)**: `Soda Core` (Raw gating) + `dbt tests` (Business rules)
- **ƒê·ªìng b·ªô Postgres ‚Üí DuckDB (EL)**: `DuckDB postgres_scanner` (kh√¥ng c·∫ßn Docker/Airbyte)
- **Bi·∫øn ƒë·ªïi d·ªØ li·ªáu (Transformation)**: `dbt-duckdb` (bi·∫øn ƒë·ªïi trong DuckDB)
- **API & Giao di·ªán (Presentation)**: `FastAPI` & `Vanilla JS`
- **Tr·ª±c quan h√≥a (BI)**: `Apache Superset`

```mermaid
flowchart TD
    subgraph ingestion["üîÑ Data Ingestion"]
        spiders["üï∑Ô∏è CrawlJob Spiders"]
        airflow["‚ö° Apache Airflow"]
    end
    subgraph storage["üíæ Data Storage"]
        postgres["üêò PostgreSQL (OLTP)"]
        duckdb["ü¶Ü DuckDB (OLAP)"]
    end
    subgraph processing["‚öôÔ∏è Data Processing"]
        soda["üß™ Soda Core (Gate Raw)"]
        scanner["üîå DuckDB postgres_scanner (Sync)"]
        dbt["üî® dbt-duckdb (Transform + Tests)"]
    end
    subgraph presentation["üìä Presentation & Access"]
        superset["Apache Superset (BI)"]
        fastapi["üöÄ FastAPI (API)"]
        webapp["üåê Web App"]
    end
    airflow --> spiders --> postgres
    airflow --> soda --> postgres
    airflow --> scanner --> duckdb
    airflow --> dbt
    dbt --> duckdb
    fastapi --> postgres
    webapp --> fastapi
    superset --> duckdb
```

## üöÄ B·∫Øt ƒë·∫ßu nhanh (Getting Started)

### Y√™u c·∫ßu
- Python 3.10+
- Docker & Docker Compose (ch·ªâ cho Postgres local)
- Git

### C√†i ƒë·∫∑t & C·∫•u h√¨nh

Th·ª±c hi·ªán c√°c b∆∞·ªõc sau theo ƒë√∫ng th·ª© t·ª± ƒë·ªÉ c√†i ƒë·∫∑t m√¥i tr∆∞·ªùng development.

**1. Clone Repository**
```bash
git clone <your-repository-url>
cd CrawlJob
```

**2. T·∫°o v√† k√≠ch ho·∫°t M√¥i tr∆∞·ªùng ·∫£o**
```bash
# T·∫°o m√¥i tr∆∞·ªùng ·∫£o
python -m venv .venv

# K√≠ch ho·∫°t (Windows)
.\.venv\Scripts\activate
```

**3. C√†i ƒë·∫∑t c√°c g√≥i ph·ª• thu·ªôc**
```bash
pip install -r requirements.txt
```

**4. C·∫•u h√¨nh Bi·∫øn m√¥i tr∆∞·ªùng**
Copy file `.env.example` th√†nh file `.env` v√† ƒëi·ªÅn c√°c th√¥ng tin c·∫ßn thi·∫øt.
```bash
# Windows
copy .env.example .env
```
Sau ƒë√≥, m·ªü file `.env` v√† ƒëi·ªÅn th√¥ng tin ƒëƒÉng nh·∫≠p PostgreSQL, ƒë∆∞·ªùng d·∫´n DUCKDB_PATH, v.v.

**5. Kh·ªüi ƒë·ªông Database**
D·ª± √°n s·ª≠ d·ª•ng PostgreSQL ch·∫°y trong Docker. H√£y kh·ªüi ƒë·ªông container:
```bash
docker-compose up -d
```
L·ªánh n√†y s·∫Ω kh·ªüi ƒë·ªông m·ªôt service PostgreSQL c√≥ th·ªÉ truy c·∫≠p t·∫°i `localhost:5432`.

**6. Ch·∫°y th·ª≠ nghi·ªám**
B√¢y gi·ªù b·∫°n ƒë√£ s·∫µn s√†ng! H√£y th·ª≠ ch·∫°y m·ªôt spider ƒë·ªÉ ki·ªÉm tra:
```bash
python run_spider.py --spider itviec --keyword "Data Engineer"
```
D·ªØ li·ªáu s·∫Ω ƒë∆∞·ª£c thu th·∫≠p v√† l∆∞u v√†o database PostgreSQL c·ªßa b·∫°n.

## üìñ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng

### Ch·∫°y Spiders
S·ª≠ d·ª•ng script `run_spider.py` ƒë·ªÉ th·ª±c thi vi·ªác thu th·∫≠p d·ªØ li·ªáu.

```bash
# Ch·∫°y m·ªôt spider c·ª• th·ªÉ
python run_spider.py --spider topcv --keyword "Product Manager"

# Ch·∫°y t·∫•t c·∫£ 10 spiders
python run_spider.py --spider all --keyword "IT"
```

### Ch·∫°y API Server
API cung c·∫•p d·ªØ li·ªáu ƒë√£ thu th·∫≠p cho giao di·ªán web.
```bash
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```
- **Health check**: `http://localhost:8000/health`
- **T√¨m ki·∫øm jobs**: `http://localhost:8000/jobs?keyword=python`

### Ki·ªÉm tra ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu (Data Quality)
√Åp d·ª•ng m√¥ h√¨nh ki·ªÉm tra hai l·ªõp + ƒë·ªìng b·ªô:

- L·ªõp 1 (Raw Gating - Soda Core): ki·ªÉm tra b·∫£ng `raw` ngay sau khi crawl ƒë·ªÉ ƒë·∫£m b·∫£o d·ªØ li·ªáu s·∫µn s√†ng.
```bash
# V√≠ d·ª• (ch·∫°y th·ªß c√¥ng)
soda scan -d job_database -c soda/configuration.yml soda/checks/raw_jobs_check1.yml
soda scan -d job_database -c soda/configuration.yml soda/checks/raw_jobs_check2.yml
soda scan -d job_database -c soda/configuration.yml soda/checks/raw_jobs_check3.yml
```

- ƒê·ªìng b·ªô (EL) sang DuckDB: d√πng DuckDB postgres_scanner (script `scripts/sync_pg_to_duckdb.py`).
```bash
# Full refresh
set SYNC_MODE=full & python scripts/sync_pg_to_duckdb.py
# Incremental theo c·ªôt scraped_at (m·∫∑c ƒë·ªãnh)
python scripts/sync_pg_to_duckdb.py
```

- L·ªõp 2 (Business Validation - dbt tests): ch·∫°y c√°c ki·ªÉm tra cho c√°c model sau khi `dbt run` trong DuckDB.
```bash
# V√≠ d·ª• v·ªõi dbt-duckdb
cd path/to/dbt_duckdb_project
 dbt run && dbt test
```

## üõ†Ô∏è C√¥ng ngh·ªá s·ª≠ d·ª•ng

- **Scrapy & Selenium**: L√µi thu th·∫≠p d·ªØ li·ªáu, v·ªõi kh·∫£ nƒÉng v∆∞·ª£t qua Cloudflare.
- **PostgreSQL & Docker**: L∆∞u tr·ªØ d·ªØ li·ªáu th√¥, d·ªÖ d√†ng c√†i ƒë·∫∑t v√† qu·∫£n l√Ω.
- **DuckDB postgres_scanner**: ƒê·ªìng b·ªô tr·ª±c ti·∫øp Postgres ‚Üí DuckDB, kh√¥ng c·∫ßn Docker cho connector.
- **Soda Core + dbt tests**: ƒê·∫£m b·∫£o t√≠nh to√†n v·∫πn v√† ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu (raw + transformed).
- **FastAPI**: X√¢y d·ª±ng API hi·ªáu nƒÉng cao.
- **V√† c√°c c√¥ng c·ª• kh√°c trong DE Stack**: Airflow, dbt, DuckDB, Superset.

## ü§ù ƒê√≥ng g√≥p
N·∫øu b·∫°n c√≥ √Ω t∆∞·ªüng c·∫£i thi·ªán d·ª± √°n, ƒë·ª´ng ng·∫ßn ng·∫°i t·∫°o Pull Request ho·∫∑c m·ªü m·ªôt Issue.
