# ğŸš€ **DATA ENGINEERING STACK IMPLEMENTATION PLAN**
## **CrawlJob: Professional Data Engineering Project**

---

## ğŸ“‹ **TABLE OF CONTENTS**

1. [ğŸ¯ Project Overview](#-project-overview)
2. [ğŸ—ï¸ Architecture Design](#ï¸-architecture-design)

---

## ğŸ¯ **PROJECT OVERVIEW**

### **Current Status**
- âœ… **10 Spiders** hoáº¡t Ä‘á»™ng hoÃ n háº£o
- âœ… **PostgreSQL** database vá»›i 10,000+ records
- âœ… **FastAPI** backend vá»›i REST endpoints
- âœ… **Web Dashboard** vá»›i Bootstrap 5
- âœ… **Automated daily crawling**

### **Data Engineering Goal**
Chuyá»ƒn Ä‘á»•i CrawlJob thÃ nh **Professional Data Engineering Project** vá»›i:
- **Apache Airflow**: Workflow orchestration
- **dbt**: Data transformation layer
- **Great Expectations**: Data quality validation
- **Power BI**: Data visualization vÃ  analytics

### **Benefits**
- ğŸ¢ **Professional**: Industry-standard data engineering stack
- ğŸ“Š **Advanced Analytics**: Rich dashboards vÃ  insights
- ğŸ”§ **Automation**: Fully automated pipelines
- ğŸ“ˆ **Scalability**: Easy to scale as project grows
- ğŸ’¼ **Career Growth**: Valuable skills for data engineering

---

## ğŸ—ï¸ **ARCHITECTURE DESIGN**

### **Current Architecture**
```
CrawlJob Spiders â†’ PostgreSQL â†’ FastAPI â†’ Web Dashboard
```

### **Target Data Engineering Architecture**

#### **Detailed Data Flow**

```mermaid
flowchart TD
    %% Layers
    subgraph ingestion["ğŸ”„ Data Ingestion"]
        spiders["ğŸ•·ï¸ CrawlJob Spiders<br/>10 Job Sites"]
        airflow["âš¡ Apache Airflow<br/>Orchestrator (Schedules/Triggers)"]
    end

    subgraph storage["ğŸ’¾ Data Storage"]
        postgres["ğŸ˜ PostgreSQL<br/>Raw & Serving (OLTP)"]
        duckdb["ğŸ¦† DuckDB<br/>Analytics Marts (OLAP)"]
    end

    subgraph processing["âš™ï¸ Data Processing"]
        dbt["ğŸ”¨ dbt<br/>Transform & Model (ELT)"]
        ge["âœ… Great Expectations<br/>Validation & Data Docs"]
    end

    subgraph presentation["ğŸ“Š Presentation & Access"]
        powerbi["ğŸ“ˆ Power BI<br/>BI Dashboards"]
        fastapi["ğŸš€ FastAPI<br/>REST API"]
        webapp["ğŸŒ Job Search Website<br/>End-User Portal"]
        ge_docs["ğŸ“‹ GE Data Docs<br/>Quality Reports"]
    end

    %% Orchestration (control-plane)
    airflow -. trigger .-> spiders
    airflow -. run .-> ge
    airflow -. run .-> dbt

    %% Data plane
    spiders -->|"Insert Raw Jobs"| postgres
    ge -->|"Validate Raw &/or Marts"| postgres
    ge -->|"Publish"| ge_docs
    dbt -->|"Read from Postgres"| postgres
    dbt -->|"Materialize Marts"| duckdb

    %% Serving
    fastapi -->|"Query"| postgres
    webapp -->|"Use"| fastapi
    powerbi -->|"Connect"| duckdb

    %% Styles
    classDef ingestionStyle fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef storageStyle fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef processStyle fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef presentStyle fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px

    class spiders,airflow ingestionStyle
    class postgres,duckdb storageStyle
    class dbt,ge processStyle
    class powerbi,fastapi,webapp,ge_docs presentStyle
```

#### Data Flow chi tiáº¿t cho Power BI

1) Äiá»u phá»‘i theo lá»‹ch (Airflow)
- Airflow cháº¡y theo lá»‹ch (vÃ­ dá»¥ 02:00 háº±ng ngÃ y) vÃ  láº§n lÆ°á»£t trigger cÃ¡c bÆ°á»›c: cháº¡y spiders â†’ kiá»ƒm tra cháº¥t lÆ°á»£ng (GE) â†’ biáº¿n Ä‘á»•i dá»¯ liá»‡u (dbt) â†’ cáº­p nháº­t kho OLAP (DuckDB).

2) Thu tháº­p dá»¯ liá»‡u (Spiders â†’ PostgreSQL)
- CÃ¡c spiders thu tháº­p dá»¯ liá»‡u tá»« 10 trang, chuáº©n hÃ³a tá»‘i thiá»ƒu vÃ  ghi trá»±c tiáº¿p vÃ o PostgreSQL (schema/raw), kÃ¨m timestamps/metadata phá»¥c vá»¥ kiá»ƒm soÃ¡t phiÃªn crawl.

3) Kiá»ƒm tra cháº¥t lÆ°á»£ng (Great Expectations â€“ Gate)
- GE cháº¡y trÃªn báº£ng raw á»Ÿ PostgreSQL: kiá»ƒm tra khÃ´ng null cÃ¡c trÆ°á»ng quan trá»ng, tÃ­nh duy nháº¥t (job_url), Ä‘á»™ má»›i (posted_date), vÃ  khá»‘i lÆ°á»£ng dá»¯ liá»‡u.
- Náº¿u FAIL: Airflow dá»«ng pipeline, gá»­i cáº£nh bÃ¡o; dá»¯ liá»‡u OLAP cÅ© váº«n Ä‘Æ°á»£c giá»¯ nguyÃªn Ä‘á»ƒ dashboard Power BI khÃ´ng bá»‹ áº£nh hÆ°á»Ÿng.
- Náº¿u PASS: tiáº¿p tá»¥c bÆ°á»›c biáº¿n Ä‘á»•i. (TÃ¹y chá»n) CÃ³ thá»ƒ cháº¡y thÃªm GE sau-transform Ä‘á»ƒ kiá»ƒm tra cÃ¡c báº£ng marts.

4) Biáº¿n Ä‘á»•i dá»¯ liá»‡u (dbt â€“ ELT)
- dbt Ä‘á»c dá»¯ liá»‡u tá»« PostgreSQL (raw) â†’ táº¡o cÃ¡c mÃ´ hÃ¬nh staging/dim/fact/agg.
- Káº¿t quáº£ Ä‘Æ°á»£c materialize vÃ o DuckDB (OLAP) thÃ nh cÃ¡c báº£ng/khung nhÃ¬n analytics-ready.

5) Kho phÃ¢n tÃ­ch (DuckDB â€“ OLAP)
- DuckDB lÆ°u trá»¯ cÃ¡c mÃ´ hÃ¬nh phá»¥c vá»¥ phÃ¢n tÃ­ch (vÃ­ dá»¥: dim_companies, fct_jobs, agg_jobs_by_industryâ€¦).
- File DuckDB Ä‘Æ°á»£c Ä‘áº·t táº¡i má»™t Ä‘Æ°á»ng dáº«n á»•n Ä‘á»‹nh Ä‘á»ƒ phá»¥c vá»¥ káº¿t ná»‘i tá»« Power BI.

6) Káº¿t ná»‘i Power BI
- Power BI káº¿t ná»‘i tá»›i DuckDB Ä‘á»ƒ Ä‘á»c cÃ¡c báº£ng phÃ¢n tÃ­ch. TÃ¹y chá»n káº¿t ná»‘i:
    - ODBC Driver cá»§a DuckDB (khuyáº¿n nghá»‹ trÃªn Windows), hoáº·c
    - Xuáº¥t Parquet tá»« DuckDB vÃ  dÃ¹ng Power BI Ä‘á»c thÆ° má»¥c Parquet, hoáº·c
    - (PhÆ°Æ¡ng Ã¡n thay tháº¿) Náº¿u Ä‘á»ƒ marts trong PostgreSQL, Power BI cÃ³ thá»ƒ káº¿t ná»‘i trá»±c tiáº¿p PostgreSQL.

7) LÃ m má»›i dá»¯ liá»‡u (Refresh)
- Desktop: Refresh thá»§ cÃ´ng Ä‘á»ƒ phÃ¡t triá»ƒn/kiá»ƒm thá»­.
- Service: DÃ¹ng On-premises Data Gateway Ä‘á»ƒ Ä‘áº·t lá»‹ch refresh sau khi Airflow hoÃ n táº¥t pipeline (vÃ­ dá»¥ 04:00). Dataset trá» tá»›i cÃ¹ng nguá»“n (ODBC/file path/Parquet folder).

8) TrÃ¬nh bÃ y vÃ  tiÃªu thá»¥
- Power BI sá»­ dá»¥ng cÃ¡c báº£ng trong DuckDB Ä‘á»ƒ dá»±ng dashboard (Jobs by Industry, Salary Distribution, Trendsâ€¦). NgÆ°á»i dÃ¹ng xem dashboard trÃªn Power BI Service/app.

9) á»¨ng dá»¥ng web ngÆ°á»i dÃ¹ng (khÃ´ng liÃªn quan Power BI)
- Job Search Website truy cáº­p dá»¯ liá»‡u qua FastAPI â†’ PostgreSQL (OLTP) Ä‘á»ƒ phá»¥c vá»¥ tra cá»©u/tÃ¬m kiáº¿m theo thá»i gian thá»±c; khÃ´ng truy váº¥n DuckDB.

```mermaid
flowchart LR
    Airflow[Apache Airflow] -. trigger .-> Spiders[CrawlJob Spiders]
    Spiders -->|Raw jobs| Postgres[(PostgreSQL OLTP)]
    Airflow -. run .-> GE[Great Expectations]
    GE -->|Validate raw| Postgres
    Airflow -. run .-> dbt[dbt]
    dbt -->|Read| Postgres
    dbt -->|Materialize marts| DuckDB[(DuckDB OLAP)]
    PowerBI[Power BI] -->|Connect| DuckDB

    classDef c1 fill:#e1f5fe,stroke:#01579b,stroke-width:1px
    classDef c2 fill:#f3e5f5,stroke:#4a148c,stroke-width:1px
    class Airflow,Spiders c1
    class Postgres,DuckDB c2
```

#### Data Flow chi tiáº¿t cho Job Search Website

1) NgÆ°á»i dÃ¹ng â†’ Giao diá»‡n Web (Frontend)
- NgÆ°á»i dÃ¹ng nháº­p tá»« khÃ³a/bá»™ lá»c (keyword, site, location, page, page_size, sortâ€¦). Giao diá»‡n gá»­i HTTP request tá»›i FastAPI.

2) Frontend â†’ FastAPI (API Layer)
- Endpoint chÃ­nh: `GET /jobs` vá»›i cÃ¡c query params Ä‘Ã£ há»— trá»£: `keyword`, `site`, `page`, `page_size` (cÃ³ thá»ƒ má»Ÿ rá»™ng `location`, `sort_by`).
- FastAPI validate tham sá»‘, chuáº©n hÃ³a, log truy váº¥n, Ã¡p háº¡n má»©c page_size an toÃ n (vÃ­ dá»¥ 10â€“50).

3) FastAPI â†’ PostgreSQL (Query OLTP)
- API dá»±ng cÃ¢u truy váº¥n cÃ³ paginate (LIMIT/OFFSET) vÃ  cÃ¡c Ä‘iá»u kiá»‡n lá»c; dÃ¹ng truy váº¥n tham sá»‘ (parameterized) Ä‘á»ƒ an toÃ n.
- Khuyáº¿n nghá»‹ chá»‰ má»¥c (indexes): `(job_title)`, `(company_name)`, `(location)`, `(posted_date)`, vÃ  `(source_site, posted_date)` Ä‘á»ƒ tá»‘i Æ°u lá»c/sáº¯p xáº¿p.

4) PostgreSQL â†’ FastAPI (Káº¿t quáº£)
- PostgreSQL tráº£ vá» danh sÃ¡ch job chuáº©n hÃ³a (18+ fields) cÃ¹ng tá»•ng sá»‘ báº£n ghi (total) náº¿u cÃ³ truy váº¥n Ä‘áº¿m.
- FastAPI tráº£ JSON vá» frontend theo schema: `items`, `total`, `page`, `page_size`.

5) FastAPI â†’ Frontend (Hiá»ƒn thá»‹)
- Frontend render danh sÃ¡ch viá»‡c lÃ m, phÃ¢n trang/scroll, vÃ  hiá»ƒn thá»‹ metadata (source_site, scraped_at, posted_dateâ€¦).
- Cho tráº£i nghiá»‡m tá»‘t hÆ¡n: debounce tÃ¬m kiáº¿m, hiá»ƒn thá»‹ loader, giá»¯ state bá»™ lá»c.

6) TÃ­nh tÆ°Æ¡i dá»¯ liá»‡u
- Dá»¯ liá»‡u Ä‘á»c tá»« PostgreSQL Ä‘Ã£ Ä‘Æ°á»£c Ä‘i qua pipeline Airflow vÃ  cá»•ng GE (cháº¥t lÆ°á»£ng Ä‘áº¡t chuáº©n) trÆ°á»›c Ä‘Ã³.
- Web luÃ´n Ä‘á»c nguá»“n OLTP nÃªn khÃ´ng bá»‹ phá»¥ thuá»™c vÃ o DuckDB/BI.

7) Äá»™ tin cáº­y & Hiá»‡u nÄƒng
- Timeout há»£p lÃ½ táº¡i API (vÃ­ dá»¥ 3â€“5s), retry nháº¹ phÃ­a frontend; phÃ¢n trang báº¯t buá»™c Ä‘á»ƒ báº£o vá»‡ DB.
- (TÃ¹y chá»n) Cache ngáº¯n háº¡n táº¡i API (in-memory/ETag) cho truy váº¥n láº·p láº¡i; báº­t nÃ©n (gzip) khi tráº£ JSON.

8) Nháº­t kÃ½ & GiÃ¡m sÃ¡t
- Log request/response vÃ  thá»i gian truy váº¥n (latency) Ä‘á»ƒ tá»‘i Æ°u tiáº¿p; theo dÃµi lá»—i 4xx/5xx.

```mermaid
flowchart LR
    User[End User] --> UI[Web UI]
    UI -->|HTTP GET /jobs?query...| FastAPI[FastAPI API]
    FastAPI -->|Parameterized SQL| Postgres[(PostgreSQL OLTP)]
    Postgres -->|Rows + total| FastAPI
    FastAPI -->|JSON items,total,page,page_size| UI

    classDef api fill:#e8f5e8,stroke:#1b5e20,stroke-width:1px
    classDef db fill:#f3e5f5,stroke:#4a148c,stroke-width:1px
    class FastAPI,UI api
    class Postgres db
```

#### Data Flow chi tiáº¿t cho Orchestration & Monitoring (Airflow)

1) LÃªn lá»‹ch & Ä‘iá»u phá»‘i
- Airflow DAG cháº¡y theo cron (vÃ­ dá»¥ 02:00). CÃ¡c task: `run_spiders` â†’ `ge_validate_raw` â†’ `dbt_run` â†’ (tuá»³ chá»n) `ge_validate_marts` â†’ `publish_duckdb` â†’ `notify_success`.

2) Retry & SLA
- Má»—i task cÃ³ `retries` vÃ  `retry_delay` há»£p lÃ½; Ä‘áº·t `sla` Ä‘á»ƒ cáº£nh bÃ¡o khi quÃ¡ thá»i gian.

3) Logging & Artifacts
- Log chi tiáº¿t cá»§a tá»«ng task Ä‘Æ°á»£c lÆ°u vÃ o thÆ° má»¥c logs; artifacts gá»“m GE Data Docs, file DuckDB má»›i, vÃ  dbt target (manifest/run_results).

4) Alerting
- KÃªnh cáº£nh bÃ¡o: Email/Slack khi task fail/SLA miss. Ná»™i dung Ä‘Ã­nh kÃ¨m link log vÃ  Data Docs (náº¿u cÃ³).

5) Observability
- Theo dÃµi tráº¡ng thÃ¡i DAG trÃªn Airflow UI (Gantt/Graph). Ghi nháº­n metrics (thá»i gian cháº¡y, tá»‰ lá»‡ fail) Ä‘á»ƒ tá»‘i Æ°u.

```mermaid
flowchart TD
    start([Scheduled 02:00]) --> run_spiders[Task: run_spiders]
    run_spiders --> ge_raw[Task: ge_validate_raw]
    ge_raw -->|PASS| dbt_run[Task: dbt_run]
    ge_raw -->|FAIL| alert1([Alert + Stop])
    dbt_run --> ge_marts{Run ge_validate_marts?}
    ge_marts -->|YES| ge_marts_task[Task: ge_validate_marts] --> publish[Task: publish_duckdb]
    ge_marts -->|NO| publish
    publish --> notify[Task: notify_success]

    classDef t fill:#fff3e0,stroke:#e65100,stroke-width:1px
    class run_spiders,ge_raw,dbt_run,ge_marts_task,publish,notify t
```

#### Data Flow chi tiáº¿t cho Data Quality (Great Expectations â€“ chi tiáº¿t)

1) Cáº¥u hÃ¬nh
- Khai bÃ¡o datasource trá» vá» PostgreSQL (raw) vÃ  (tuá»³ chá»n) DuckDB (marts). Táº¡o expectation suites cho cÃ¡c báº£ng quan trá»ng.

2) Cháº¡y checkpoint
- Airflow trigger checkpoints: `raw_jobs_checkpoint` trÆ°á»›c dbt; `marts_checkpoint` sau dbt (tuá»³ chá»n). Káº¿t quáº£ gá»“m pass/fail + thá»‘ng kÃª chi tiáº¿t.

3) Data Docs
- Tá»± Ä‘á»™ng build Data Docs (HTML) vÃ  lÆ°u á»Ÿ má»™t vá»‹ trÃ­ cá»‘ Ä‘á»‹nh (vÃ­ dá»¥ `reports/ge_data_docs/`). CÃ³ thá»ƒ publish lÃªn web ná»™i bá»™ náº¿u cáº§n.

4) Gating
- Náº¿u checkpoint FAIL (vÃ­ dá»¥ null/unique/freshness vi pháº¡m), dá»«ng pipeline vÃ  gá»­i alert; khÃ´ng cáº­p nháº­t DuckDB Ä‘á»ƒ giá»¯ dashboard á»•n Ä‘á»‹nh.

```mermaid
flowchart TD
    GE[GE Checkpoint] --> RAW[(PostgreSQL raw)]
    RAW --> VALIDATE{Validate rules}
    VALIDATE -- PASS --> DOCS[Build Data Docs]
    VALIDATE -- FAIL --> ALERT[Alert and stop pipeline]
    DOCS --> PUBLISH[Publish HTML Data Docs]
```

#### Data Flow chi tiáº¿t cho dbt Docs & Lineage

1) Sinh tÃ i liá»‡u
- Cháº¡y `dbt docs generate` sau `dbt run` Ä‘á»ƒ táº¡o catalog + lineage diagrams; lÆ°u trong `target/` vÃ  (tuá»³ chá»n) publish ná»™i bá»™.

2) Exposures
- Khai bÃ¡o `exposures` trong dbt Ä‘á»ƒ mÃ´ táº£ dashboard Power BI vÃ  web app nhÆ° consumer chÃ­nh; giÃºp theo dÃµi tÃ¡c Ä‘á»™ng thay Ä‘á»•i.

3) Source Freshness
- Cháº¡y `dbt source freshness` theo lá»‹ch Ä‘á»ƒ Ä‘o Ä‘á»™ tÆ°Æ¡i cá»§a nguá»“n (PostgreSQL/raw), pháº£n há»“i vÃ o monitoring/alerting.

```mermaid
flowchart TD
    dbt_run[dbt run] --> models[Staging/Dim/Fact/Agg Models]
    dbt_run --> target_duckdb[(DuckDB marts)]
    dbt_docs[dbt docs generate] --> catalog[Catalog + Lineage]
    exposures[dbt exposures] --> consumers[Power BI, Web App]
    freshness[dbt source freshness] --> status[Freshness Status]
```

#### Data Flow chi tiáº¿t cho Data Export/Sharing (Parquet/External)

1) Export tá»« DuckDB
- Sau `dbt run`, cÃ³ thá»ƒ export báº£ng phÃ¢n tÃ­ch tá»« DuckDB sang Parquet/CSV trong `data/exports/` Ä‘á»ƒ chia sáº» cho data science/Ä‘á»‘i tÃ¡c.

2) TÃ­ch há»£p cÃ´ng cá»¥ khÃ¡c
- CÃ¡c cÃ´ng cá»¥ nhÆ° Pandas, Spark, hoáº·c Power BI (qua Parquet folder) cÃ³ thá»ƒ tiÃªu thá»¥ dá»¯ liá»‡u nÃ y mÃ  khÃ´ng cáº§n truy cáº­p trá»±c tiáº¿p DB.

3) Quáº£n trá»‹ phiÃªn báº£n
- Äáº·t quy táº¯c Ä‘áº·t tÃªn (kÃ¨m timestamp) vÃ  dá»n dáº¹p phiÃªn báº£n cÅ© báº±ng job Ä‘á»‹nh ká»³ Ä‘á»ƒ tá»‘i Æ°u dung lÆ°á»£ng.

```mermaid
flowchart TD
    MARTS["DuckDB marts"] --> EXPORT["Export to Parquet or CSV"]
    EXPORT --> PANDAS["Pandas"]
    EXPORT --> SPARK["Spark"]
    EXPORT --> PBI["Power BI - Parquet folder"]
    AF["Airflow optional"] --> EXPORT
```

### **Technology Stack**
- **Orchestration**: Apache Airflow
- **OLTP Database**: PostgreSQL
- **OLAP Database**: DuckDB
- **Transformation**: dbt
- **Data Quality**: Great Expectations
- **Visualization**: Power BI
- **Backend**: FastAPI
- **Frontend**: Bootstrap 5
- **Containerization**: Docker
- **Version Control**: Git & GitHub